{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem4 - (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load MovieLens-1M dataset (assuming ratings.dat is used)\n",
    "column_names = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "ratings = pd.read_csv(\"/Users/luninghao/Desktop/CSCI-SHU-381-Recsys/CA1_ProblemSet/ml-1m/ratings.dat\", sep=\"::\", names=column_names, engine=\"python\")\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "ratings[\"timestamp\"] = pd.to_datetime(ratings[\"timestamp\"], unit=\"s\")\n",
    "\n",
    "# Sort by user and timestamp\n",
    "ratings = ratings.sort_values(by=[\"user_id\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Leave-One_Last Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_last_split(ratings):\n",
    "    train_list = []\n",
    "    valid_list = []\n",
    "    test_list = []\n",
    "\n",
    "    # Group by user_id\n",
    "    for user, data in ratings.groupby(\"user_id\"):\n",
    "        if len(data) >= 2:\n",
    "            train = data.iloc[:-2]  # All but last two interactions\n",
    "            valid = data.iloc[-2:-1]  # Second-to-last interaction\n",
    "            test = data.iloc[-1:]  # Last interaction\n",
    "        else:\n",
    "            train = data.iloc[:-1]  # If only one interaction, assign to train\n",
    "            valid = data.iloc[-1:]  # Assign the last to validation\n",
    "            test = pd.DataFrame(columns=ratings.columns)  # No test sample\n",
    "\n",
    "        train_list.append(train)\n",
    "        valid_list.append(valid)\n",
    "        test_list.append(test)\n",
    "\n",
    "    # Combine all users\n",
    "    train_set = pd.concat(train_list)\n",
    "    valid_set = pd.concat(valid_list)\n",
    "    test_set = pd.concat(test_list)\n",
    "\n",
    "    return train_set, valid_set, test_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temporal Global Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_global_split(ratings, cutoff=\"2002-01-01 00:00:00\"):\n",
    "    cutoff_date = pd.to_datetime(cutoff)\n",
    "\n",
    "    # Train set: interactions before the cutoff\n",
    "    train_set = ratings[ratings[\"timestamp\"] < cutoff_date]\n",
    "\n",
    "    # Split last 10% of train interactions as validation\n",
    "    valid_size = int(len(train_set) * 0.1)\n",
    "    valid_set = train_set.tail(valid_size)\n",
    "    train_set = train_set.iloc[:-valid_size]\n",
    "\n",
    "    # Test set: interactions after the cutoff\n",
    "    test_set = ratings[ratings[\"timestamp\"] >= cutoff_date]\n",
    "\n",
    "    return train_set, valid_set, test_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "train_lol, valid_lol, test_lol = leave_one_last_split(ratings)\n",
    "train_tg, valid_tg, test_tg = temporal_global_split(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Split</th>\n",
       "      <th># Users</th>\n",
       "      <th># Items</th>\n",
       "      <th># Interactions (train)</th>\n",
       "      <th># Interactions (valid)</th>\n",
       "      <th># Interactions (test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leave-One-Last</td>\n",
       "      <td>6040</td>\n",
       "      <td>3706</td>\n",
       "      <td>988129</td>\n",
       "      <td>6040</td>\n",
       "      <td>6040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Temporal Global</td>\n",
       "      <td>6040</td>\n",
       "      <td>3706</td>\n",
       "      <td>875534</td>\n",
       "      <td>97281</td>\n",
       "      <td>27394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Data Split  # Users  # Items  # Interactions (train)  \\\n",
       "0   Leave-One-Last     6040     3706                  988129   \n",
       "1  Temporal Global     6040     3706                  875534   \n",
       "\n",
       "   # Interactions (valid)  # Interactions (test)  \n",
       "0                    6040                   6040  \n",
       "1                   97281                  27394  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute statistics\n",
    "def dataset_statistics(train, valid, test, name):\n",
    "    num_users = len(pd.concat([train, valid, test])[\"user_id\"].unique())\n",
    "    num_items = len(pd.concat([train, valid, test])[\"movie_id\"].unique())\n",
    "    num_interactions = (len(train), len(valid), len(test))\n",
    "    return [name, num_users, num_items] + list(num_interactions)\n",
    "\n",
    "# Create statistics table\n",
    "stats_table = pd.DataFrame(\n",
    "    [\n",
    "        dataset_statistics(train_lol, valid_lol, test_lol, \"Leave-One-Last\"),\n",
    "        dataset_statistics(train_tg, valid_tg, test_tg, \"Temporal Global\"),\n",
    "    ],\n",
    "    columns=[\"Data Split\", \"# Users\", \"# Items\", \"# Interactions (train)\", \"# Interactions (valid)\", \"# Interactions (test)\"]\n",
    ")\n",
    "\n",
    "stats_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem4 - (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from annoy import AnnoyIndex\n",
    "from sklearn.preprocessing import normalize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
